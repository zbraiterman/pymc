
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GLM: Hierarchical Linear Regression &#8212; PyMC3 3.10.0 documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/semantic-sphinx.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/semantic-ui@2.4.2/dist/semantic.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/default.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <script src="../_static/highlight.min.js"></script>
    <script src="../_static/semantic.min.js"></script>
    <link rel="shortcut icon" href="../_static/PyMC3.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<script>
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-176578023-1']);
  _gaq.push(['_trackPageview']);
</script>
<script>hljs.initHighlightingOnLoad();</script>
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">



  </head><body>
<div class="ui vertical center aligned">

    <div class="ui container">
        <div class="ui large secondary pointing menu">
            <a class="item" href="/">
                <img class="ui bottom aligned tiny image" src="https://cdn.rawgit.com/pymc-devs/pymc3/master/docs/logos/svg/PyMC3_banner.svg" />
            </a>
             <a href="../nb_tutorials/index.html" class="item">Tutorials</a> <a href="../nb_examples/index.html" class="item">Examples</a> <a href="../learn.html" class="item">Books + Videos</a> <a href="../api.html" class="item">API</a> <a href="../developer_guide.html" class="item">Developer Guide</a> <a href="../about.html" class="item">About PyMC3</a>
            
            <div class="right menu">
                <div class="item">
                    <form class="ui icon input" action="../search.html" method="get">
                        <input type="text" placeholder="Search..." name="q" />
                        <i class="search link icon"></i>
                    </form>
                </div>
                <a class="item" href="https://github.com/pymc-devs/pymc3"><i class="github blue icon large"></i></a>
            </div>
        </div>
    </div>
    
</div>

<div class="ui container" role="main">
    

    <div class="ui vertical segment">
        
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="GLM:-Hierarchical-Linear-Regression">
<h1>GLM: Hierarchical Linear Regression<a class="headerlink" href="#GLM:-Hierarchical-Linear-Regression" title="Permalink to this headline">¶</a></h1>
<ol class="loweralpha simple" start="3">
<li><p>2016 by Danne Elbers, Thomas Wiecki</p></li>
</ol>
<p>This tutorial is adapted from a <a class="reference external" href="http://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/">blog post by Danne Elbers and Thomas Wiecki called “The Best Of Both Worlds: Hierarchical Linear Regression in PyMC3”</a>.</p>
<p>Today’s blog post is co-written by <a class="reference external" href="http://www.linkedin.com/pub/danne-elbers/69/3a2/7ba">Danne Elbers</a> who is doing her masters thesis with me on computational psychiatry using Bayesian modeling. This post also borrows heavily from a <a class="reference external" href="http://nbviewer.ipython.org/github/fonnesbeck/multilevel_modeling/blob/master/multilevel_modeling.ipynb?create=1">Notebook</a> by <a class="reference external" href="http://biostat.mc.vanderbilt.edu/wiki/Main/ChrisFonnesbeck">Chris Fonnesbeck</a>.</p>
<p>The power of Bayesian modelling really clicked for me when I was first introduced to hierarchical modelling. In this blog post we will:</p>
<ul class="simple">
<li><p>provide and intuitive explanation of hierarchical/multi-level Bayesian modeling;</p></li>
<li><p>show how this type of model can easily be built and estimated in <a class="reference external" href="https://github.com/pymc-devs/pymc">PyMC3</a>;</p></li>
<li><p>demonstrate the advantage of using hierarchical Bayesian modelling as opposed to non-hierarchical Bayesian modelling by comparing the two;</p></li>
<li><p>visualize the “shrinkage effect” (explained below); and</p></li>
<li><p>highlight connections to the frequentist version of this model.</p></li>
</ul>
<p>Having multiple sets of related measurements comes up all the time. In mathematical psychology, for example, you test multiple subjects on the same task. We then want to estimate a computational/mathematical model that describes the behavior on the task by a set of parameters. We could thus fit a model to each subject individually, assuming they share no similarities; or, pool all the data and estimate one model assuming all subjects are identical. Hierarchical modeling allows the best of both
worlds by modeling subjects’ similarities but also allowing estimiation of individual parameters. As an aside, software from our lab, <a class="reference external" href="http://ski.cog.brown.edu/hddm_docs/">HDDM</a>, allows hierarchical Bayesian estimation of a widely used decision making model in psychology. In this blog post, however, we will use a more classical example of <a class="reference external" href="http://en.wikipedia.org/wiki/Hierarchical_linear_modeling">hierarchical linear regression</a> to predict radon levels in houses.</p>
<p>This is the 3rd blog post on the topic of Bayesian modeling in PyMC3, see here for the previous two:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://twiecki.github.io/blog/2013/08/12/bayesian-glms-1/">The Inference Button: Bayesian GLMs made easy with PyMC3</a></p></li>
<li><p><a class="reference external" href="http://twiecki.github.io/blog/2013/08/27/bayesian-glms-2/">This world is far from Normal(ly distributed): Bayesian Robust Regression in PyMC3</a></p></li>
</ul>
<div class="section" id="The-data-set">
<h2>The data set<a class="headerlink" href="#The-data-set" title="Permalink to this headline">¶</a></h2>
<p>Gelman et al.’s (2007) radon dataset is a classic for hierarchical modeling. In this dataset the amount of the radioactive gas radon has been measured among different households in all counties of several states. Radon gas is known to be the highest cause of lung cancer in non-smokers. It is believed to be more strongly present in households containing a basement and to differ in amount present among types of soil. Here we’ll investigate this differences and try to make predictions of
radonlevels in different counties based on the county itself and the presence of a basement. In this example we’ll look at Minnesota, a state that contains 85 counties in which different measurements are taken, ranging from 2 to 116 measurements per county.</p>
<p><img alt="radon" src="https://upload.wikimedia.org/wikipedia/commons/b/b9/CNX_Chem_21_06_RadonExpos.png" /></p>
<p>First, we’ll load the data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">theano</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running on PyMC3 v</span><span class="si">{</span><span class="n">pm</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Running on PyMC3 v3.9.0
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;arviz-darkgrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">pm</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s2">&quot;radon.csv&quot;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;log_radon&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;log_radon&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">)</span>
<span class="n">county_names</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">county</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">county_idx</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">county_code</span><span class="o">.</span><span class="n">values</span>

<span class="n">n_counties</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">county</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>The relevant part of the data we will model looks as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">data</span><span class="p">[[</span><span class="s2">&quot;county&quot;</span><span class="p">,</span> <span class="s2">&quot;log_radon&quot;</span><span class="p">,</span> <span class="s2">&quot;floor&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>county</th>
      <th>log_radon</th>
      <th>floor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AITKIN</td>
      <td>0.832909</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AITKIN</td>
      <td>0.832909</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AITKIN</td>
      <td>1.098612</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AITKIN</td>
      <td>0.095310</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ANOKA</td>
      <td>1.163151</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>As you can see, we have multiple <code class="docutils literal notranslate"><span class="pre">radon</span></code> measurements (log-converted to be on the real line) – one row for each house – in a <code class="docutils literal notranslate"><span class="pre">county</span></code> and whether the house has a basement (<code class="docutils literal notranslate"><span class="pre">floor</span></code> == 0) or not (<code class="docutils literal notranslate"><span class="pre">floor</span></code> == 1). We are interested in whether having a basement increases the <code class="docutils literal notranslate"><span class="pre">radon</span></code> measured in the house.</p>
</div>
<div class="section" id="The-Models">
<h2>The Models<a class="headerlink" href="#The-Models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Pooling-of-measurements">
<h3>Pooling of measurements<a class="headerlink" href="#Pooling-of-measurements" title="Permalink to this headline">¶</a></h3>
<p>Now you might say: “That’s easy! I’ll just pool all my data and estimate one big regression to asses the influence of a basement across all counties”. In math-speak that model would be:</p>
<div class="math notranslate nohighlight">
\[radon_{i, c} = \alpha + \beta*\text{floor}_{i, c} + \epsilon\]</div>
<p>Where <span class="math notranslate nohighlight">\(i\)</span> represents the measurement, <span class="math notranslate nohighlight">\(c\)</span> the county and floor contains a 0 or 1 if the house has a basement or not, respectively. If you need a refresher on Linear Regressions in <code class="docutils literal notranslate"><span class="pre">PyMC</span></code>, check out my <a class="reference external" href="http://twiecki.github.io/blog/2013/08/12/bayesian-glms-1/">previous blog post</a>. Critically, we are only estimating <em>one</em> intercept and <em>one</em> slope for all measurements over all counties pooled together as illustrated in the graphic below (<span class="math notranslate nohighlight">\(\theta\)</span> represents
<span class="math notranslate nohighlight">\((\alpha, \beta)\)</span> in our case and <span class="math notranslate nohighlight">\(y_i\)</span> are the measurements of the <span class="math notranslate nohighlight">\(i\)</span>th county).</p>
<p><img alt="pooled" src="http://f.cl.ly/items/0R1W063h1h0W2M2C0S3M/Screen%20Shot%202013-10-10%20at%208.22.21%20AM.png" /></p>
</div>
<div class="section" id="Unpooled-measurements:-separate-regressions">
<h3>Unpooled measurements: separate regressions<a class="headerlink" href="#Unpooled-measurements:-separate-regressions" title="Permalink to this headline">¶</a></h3>
<p>But what if we are interested in whether different counties actually have different relationships (slope) and different base-rates of radon (intercept)? Then you might say “OK then, I’ll just estimate <span class="math notranslate nohighlight">\(n\)</span> (number of counties) different regressions – one for each county”. In math-speak that model would be:</p>
<div class="math notranslate nohighlight">
\[radon_{i, c} = \alpha_{c} + \beta_{c}*\text{floor}_{i, c} + \epsilon_c\]</div>
<p>Note that we added the subindex <span class="math notranslate nohighlight">\(c\)</span> so we are estimating <span class="math notranslate nohighlight">\(n\)</span> different <span class="math notranslate nohighlight">\(\alpha\)</span>s and <span class="math notranslate nohighlight">\(\beta\)</span>s – one for each county.</p>
<p><img alt="unpooled" src="http://f.cl.ly/items/38020n2t2Y2b1p3t0B0e/Screen%20Shot%202013-10-10%20at%208.23.36%20AM.png" /></p>
<p>This is the extreme opposite model; where above we assumed all counties are exactly the same, here we are saying that they share no similarities whatsoever. As we show below, this type of model can be very noisy when we have little data per county, as is the case in this data set.</p>
</div>
<div class="section" id="Partial-pooling:-Hierarchical-Regression-aka,-the-best-of-both-worlds">
<h3>Partial pooling: Hierarchical Regression aka, the best of both worlds<a class="headerlink" href="#Partial-pooling:-Hierarchical-Regression-aka,-the-best-of-both-worlds" title="Permalink to this headline">¶</a></h3>
<p>Fortunately, there is a middle ground to both of these extremes. Specifically, we may assume that while <span class="math notranslate nohighlight">\(\alpha\)</span>s and <span class="math notranslate nohighlight">\(\beta\)</span>s are different for each county as in the unpooled case, the coefficients all share similarity. We can model this by assuming that each individual coefficient comes from a common group distribution:</p>
<div class="math notranslate nohighlight">
\[\alpha_{c} \sim \mathcal{N}(\mu_{\alpha}, \sigma_{\alpha}^2)\]</div>
<div class="math notranslate nohighlight">
\[\beta_{c} \sim \mathcal{N}(\mu_{\beta}, \sigma_{\beta}^2)\]</div>
<p>We thus assume the intercepts <span class="math notranslate nohighlight">\(\alpha\)</span> and slopes <span class="math notranslate nohighlight">\(\beta\)</span> to come from a normal distribution centered around their respective group mean <span class="math notranslate nohighlight">\(\mu\)</span> with a certain standard deviation <span class="math notranslate nohighlight">\(\sigma^2\)</span>, the values (or rather posteriors) of which we also estimate. That’s why this is called a multilevel, hierarchical or partial-pooling modeling.</p>
<p><img alt="hierarchical" src="http://f.cl.ly/items/1B3U223i002y3V2W3r0W/Screen%20Shot%202013-10-10%20at%208.25.05%20AM.png" /></p>
<p>How do we estimate such a complex model you might ask? Well, that’s the beauty of Probabilistic Programming – we just formulate the model we want and press our <a class="reference external" href="http://twiecki.github.io/blog/2013/08/12/bayesian-glms-1/">Inference Button(TM)</a>.</p>
<p>(Note that the above is not a complete Bayesian model specification as we haven’t defined priors or hyperpriors (i.e. priors for the group distribution, <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>). These will be used in the model implementation below but only distract here.)</p>
</div>
</div>
<div class="section" id="Probabilistic-Programming">
<h2>Probabilistic Programming<a class="headerlink" href="#Probabilistic-Programming" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Unpooled/non-hierarchical-model">
<h3>Unpooled/non-hierarchical model<a class="headerlink" href="#Unpooled/non-hierarchical-model" title="Permalink to this headline">¶</a></h3>
<p>To highlight the effect of the hierarchical linear regression we’ll first estimate the non-hierarchical, unpooled Bayesian model from above (separate regressions). For each county we estimate a completely separate mean (intercept). As we have no prior information on what the intercept or regressions could be, we will be using a normal distribution centered around 0 with a wide standard-deviation to describe the intercept and regressions. We’ll assume the measurements are normally distributed
with noise <span class="math notranslate nohighlight">\(\epsilon\)</span> on which we place a uniform distribution.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">unpooled_model</span><span class="p">:</span>

    <span class="c1"># Independent parameters for each county</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_counties</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_counties</span><span class="p">)</span>

    <span class="c1"># Model error</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s2">&quot;eps&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="c1"># Model prediction of radon level</span>
    <span class="c1"># a[county_idx] translates to a[0, 0, 0, 1, 1, ...],</span>
    <span class="c1"># we thus link multiple household measures of a county</span>
    <span class="c1"># to its coefficients.</span>
    <span class="n">radon_est</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">county_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">county_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">floor</span><span class="o">.</span><span class="n">values</span>

    <span class="c1"># Data likelihood</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">radon_est</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">log_radon</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">unpooled_model</span><span class="p">:</span>
    <span class="n">unpooled_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [eps, b, a]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [12000/12000 00:17<00:00 Sampling 4 chains, 0 divergences]
</div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 18 seconds.
</pre></div></div>
</div>
</div>
<div class="section" id="Hierarchical-Model">
<h3>Hierarchical Model<a class="headerlink" href="#Hierarchical-Model" title="Permalink to this headline">¶</a></h3>
<p>Instead of creating models separatley, the hierarchical model creates group parameters that consider the countys not as completely different but as having an underlying similarity. These distributions are subsequently used to influence the distribution of each county’s <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">hierarchical_model</span><span class="p">:</span>
    <span class="c1"># Hyperpriors for group nodes</span>
    <span class="n">mu_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;mu_a&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">&quot;sigma_a&quot;</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
    <span class="n">mu_b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;mu_b&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">sigma_b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s2">&quot;sigma_b&quot;</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>

    <span class="c1"># Intercept for each county, distributed around group mean mu_a</span>
    <span class="c1"># Above we just set mu and sd to a fixed value while here we</span>
    <span class="c1"># plug in a common group distribution for all a and b (which are</span>
    <span class="c1"># vectors of length n_counties).</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu_a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_a</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_counties</span><span class="p">)</span>
    <span class="c1"># Intercept for each county, distributed around group mean mu_a</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu_b</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_b</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_counties</span><span class="p">)</span>

    <span class="c1"># Model error</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s2">&quot;eps&quot;</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>

    <span class="n">radon_est</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">county_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">county_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">floor</span><span class="o">.</span><span class="n">values</span>

    <span class="c1"># Data likelihood</span>
    <span class="n">radon_like</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s2">&quot;radon_like&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">radon_est</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">log_radon</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Inference button (TM)!</span>
<span class="k">with</span> <span class="n">hierarchical_model</span><span class="p">:</span>
    <span class="n">hierarchical_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [eps, b, a, sigma_b, mu_b, sigma_a, mu_a]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='16000' class='' max='16000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [16000/16000 01:08<00:00 Sampling 4 chains, 1,484 divergences]
</div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sampling 4 chains for 2_000 tune and 2_000 draw iterations (8_000 + 8_000 draws total) took 68 seconds.
There were 38 divergences after tuning. Increase `target_accept` or reparameterize.
The acceptance probability does not match the target. It is 0.8352266243043989, but should be close to 0.9. Try to increase the number of tuning steps.
There were 7 divergences after tuning. Increase `target_accept` or reparameterize.
There were 1439 divergences after tuning. Increase `target_accept` or reparameterize.
The acceptance probability does not match the target. It is 0.5325407823658966, but should be close to 0.9. Try to increase the number of tuning steps.
The rhat statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.
The estimated number of effective samples is smaller than 200 for some parameters.
</pre></div></div>
</div>
<p>Plotting the hierarchical model trace - its found values - from 2000 iterations onwards (right side plot) and its accumulated marginal values (left side plot)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">hierarchical_trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mu_a&quot;</span><span class="p">,</span> <span class="s2">&quot;mu_b&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma_a&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma_b&quot;</span><span class="p">,</span> <span class="s2">&quot;eps&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/dependencies/arviz/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.
  FutureWarning,
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_GLM-hierarchical_17_1.png" class="no-scaled-link" src="../_images/notebooks_GLM-hierarchical_17_1.png" style="width: 1211px; height: 1011px;" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">hierarchical_trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">],</span> <span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;a_dim_0&quot;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)});</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/dependencies/arviz/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.
  FutureWarning,
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_GLM-hierarchical_18_1.png" class="no-scaled-link" src="../_images/notebooks_GLM-hierarchical_18_1.png" style="width: 1211px; height: 211px;" />
</div>
</div>
<p>The marginal posteriors in the left column are highly informative. <code class="docutils literal notranslate"><span class="pre">mu_a</span></code> tells us the group mean (log) radon levels. <code class="docutils literal notranslate"><span class="pre">mu_b</span></code> tells us that having no basement decreases radon levels significantly (no mass above zero). We can also see by looking at the marginals for <code class="docutils literal notranslate"><span class="pre">a</span></code> that there is quite some differences in radon levels between counties (each ‘rainbow’ color corresponds to a single county); the different widths are related to how much confidence we have in each parameter estimate – the
more measurements per county, the higher our confidence will be.</p>
</div>
</div>
<div class="section" id="Posterior-Predictive-Check">
<h2>Posterior Predictive Check<a class="headerlink" href="#Posterior-Predictive-Check" title="Permalink to this headline">¶</a></h2>
<div class="section" id="The-Root-Mean-Square-Deviation">
<h3>The Root Mean Square Deviation<a class="headerlink" href="#The-Root-Mean-Square-Deviation" title="Permalink to this headline">¶</a></h3>
<p>To find out which of the models explains the data better we can calculate the Root Mean Square Deviaton (RMSD). This posterior predictive check revolves around recreating the data based on the parameters found at different moments in the chain. The recreated or predicted values are subsequently compared to the real data points, the model that predicts data points closer to the original data is considered the better one. Thus, the lower the RMSD the better.</p>
<p>When computing the RMSD (code not shown) we get the following result:</p>
<ul class="simple">
<li><p>individual/non-hierarchical model: 0.13</p></li>
<li><p>hierarchical model: 0.08</p></li>
</ul>
<p>As can be seen above the hierarchical model performs better than the non-hierarchical model in predicting the radon values. Following this, we’ll plot some examples of county’s showing the actual radon measurements, the hierarchial predictions and the non-hierarchical predictions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">selection</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;CASS&quot;</span><span class="p">,</span> <span class="s2">&quot;CROW WING&quot;</span><span class="p">,</span> <span class="s2">&quot;FREEBORN&quot;</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">selection</span><span class="p">):</span>
    <span class="n">c_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">county</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span>
    <span class="n">c_data</span> <span class="o">=</span> <span class="n">c_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">c_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">county_names</span> <span class="o">==</span> <span class="n">c</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">z</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">c_data</span><span class="p">[</span><span class="s2">&quot;county_code&quot;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">xvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">a_val</span><span class="p">,</span> <span class="n">b_val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unpooled_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][:,</span> <span class="n">c_index</span><span class="p">],</span> <span class="n">unpooled_trace</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">][:,</span> <span class="n">c_index</span><span class="p">]):</span>
        <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">a_val</span> <span class="o">+</span> <span class="n">b_val</span> <span class="o">*</span> <span class="n">xvals</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">xvals</span><span class="p">,</span>
        <span class="n">unpooled_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][:,</span> <span class="n">c_index</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">unpooled_trace</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">][:,</span> <span class="n">c_index</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> <span class="n">xvals</span><span class="p">,</span>
        <span class="s2">&quot;b&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">lw</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;individual&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">a_val</span><span class="p">,</span> <span class="n">b_val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">hierarchical_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][</span><span class="n">z</span><span class="p">],</span> <span class="n">hierarchical_trace</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">][</span><span class="n">z</span><span class="p">]):</span>
        <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">a_val</span> <span class="o">+</span> <span class="n">b_val</span> <span class="o">*</span> <span class="n">xvals</span><span class="p">,</span> <span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">xvals</span><span class="p">,</span>
        <span class="n">hierarchical_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][</span><span class="n">z</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">hierarchical_trace</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">][</span><span class="n">z</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> <span class="n">xvals</span><span class="p">,</span>
        <span class="s2">&quot;g&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">lw</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;hierarchical&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">c_data</span><span class="o">.</span><span class="n">floor</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">c_data</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="n">c_data</span><span class="o">.</span><span class="n">log_radon</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span>
        <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span>
        <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;original data&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;basement&quot;</span><span class="p">,</span> <span class="s2">&quot;no basement&quot;</span><span class="p">])</span>
    <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;log radon level&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_GLM-hierarchical_21_0.png" class="no-scaled-link" src="../_images/notebooks_GLM-hierarchical_21_0.png" style="width: 1025px; height: 522px;" />
</div>
</div>
<p>In the above plot we have the data points in black of three selected counties. The thick lines represent the mean estimate of the regression line of the individual (blue) and hierarchical model (in green). The thinner lines are regression lines of individual samples from the posterior and give us a sense of how variable the estimates are.</p>
<p>When looking at the county ‘CASS’ we see that the non-hierarchical estimation is strongly biased: as this county’s data contains only households with a basement the estimated regression produces the non-sensical result of a giant negative slope meaning that we would expect negative radon levels in a house without basement!</p>
<p>Moreover, in the example county’s ‘CROW WING’ and ‘FREEBORN’ the non-hierarchical model appears to react more strongly than the hierarchical model to the existance of outliers in the dataset (‘CROW WING’: no basement upper right. ‘FREEBORN’: basement upper left). Assuming that there should be a higher amount of radon gas measurable in households with basements opposed to those without, the county ‘CROW WING’’s non-hierachical model seems off. Having the group-distribution constrain the
coefficients we get meaningful estimates in all cases as we apply what we learn from the group to the individuals and vice-versa.</p>
</div>
</div>
<div class="section" id="Shrinkage">
<h2>Shrinkage<a class="headerlink" href="#Shrinkage" title="Permalink to this headline">¶</a></h2>
<p>Shrinkage describes the process by which our estimates are “pulled” towards the group-mean as a result of the common group distribution – county-coefficients very far away from the group mean have very low probability under the normality assumption, moving them closer to the group mean gives them higher probability. In the non-hierachical model every county is allowed to differ completely from the others by just using each county’s data, resulting in a model more prone to outliers (as shown
above).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">hier_a</span> <span class="o">=</span> <span class="n">hierarchical_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][</span><span class="mi">500</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">hier_b</span> <span class="o">=</span> <span class="n">hierarchical_trace</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">][</span><span class="mi">500</span><span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">indv_a</span> <span class="o">=</span> <span class="p">[</span><span class="n">unpooled_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][</span><span class="mi">500</span><span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">county_names</span> <span class="o">==</span> <span class="n">c</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">county_names</span><span class="p">]</span>
<span class="n">indv_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">unpooled_trace</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">][</span><span class="mi">500</span><span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">county_names</span> <span class="o">==</span> <span class="n">c</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">county_names</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span>
    <span class="mi">111</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Intercept&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Floor Measure&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Hierarchical vs. Non-hierarchical Bayes&quot;</span><span class="p">,</span>
    <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">indv_a</span><span class="p">,</span> <span class="n">indv_b</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">26</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;non-hierarchical&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">hier_a</span><span class="p">,</span> <span class="n">hier_b</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">26</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;hierarchical&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indv_b</span><span class="p">)):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span>
        <span class="n">indv_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">indv_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">hier_a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">indv_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">hier_b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">indv_b</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">fc</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span>
        <span class="n">ec</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span>
        <span class="n">length_includes_head</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
        <span class="n">head_width</span><span class="o">=</span><span class="mf">0.04</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_GLM-hierarchical_25_0.png" class="no-scaled-link" src="../_images/notebooks_GLM-hierarchical_25_0.png" style="width: 870px; height: 850px;" />
</div>
</div>
<p>In the shrinkage plot above we show the coefficients of each county’s non-hierarchical posterior mean (blue) and the hierarchical posterior mean (red). To show the effect of shrinkage on a single coefficient-pair (alpha and beta) we connect the blue and red points belonging to the same county by an arrow. Some non-hierarchical posteriors are so far out that we couldn’t display them in this plot (it makes the axes too wide). Interestingly, all hierarchical posteriors of the floor-measure seem to
be around -0.6 indicating that having a basement in almost all county’s is a clear indicator for heightened radon levels. The intercept (which we take for type of soil) appears to differ among countys. This information would have been difficult to find if we had only used the non-hierarchial model.</p>
<p>Critically, many effects that look quite large and significant in the non-hiearchical model actually turn out to be much smaller when we take the group distribution into account (this point can also well be seen in plot <code class="docutils literal notranslate"><span class="pre">In[12]</span></code> in <a class="reference external" href="http://nbviewer.ipython.org/github/fonnesbeck/multilevel_modeling/blob/master/multilevel_modeling.ipynb">Chris’ NB</a>). Shrinkage can thus be viewed as a form of smart regularization that helps reduce false-positives!</p>
<div class="section" id="Connections-to-Frequentist-statistics">
<h3>Connections to Frequentist statistics<a class="headerlink" href="#Connections-to-Frequentist-statistics" title="Permalink to this headline">¶</a></h3>
<p>This type of hierarchical, partial pooling model is known as a <a class="reference external" href="https://en.wikipedia.org/wiki/Random_effects_model">random effects model</a> in frequentist terms. Interestingly, if we placed uniform priors on the group mean and variance in the above model, the resulting Bayesian model would be equivalent to a random effects model. One might imagine that the difference between a model with uniform or wide normal hyperpriors should not have a huge impact. However, <a class="reference external" href="http://andrewgelman.com/2014/03/15/problematic-interpretations-confidence-intervals/">Gelman
says</a> encourages use of weakly-informative priors (like we did above) over flat priors.</p>
</div>
</div>
<div class="section" id="Summary">
<h2>Summary<a class="headerlink" href="#Summary" title="Permalink to this headline">¶</a></h2>
<p>In this post, co-authored by Danne Elbers, we showed how a multi-level hierarchical Bayesian model gives the best of both worlds when we have multiple sets of measurements we expect to have similarity. The naive approach either pools all data together and ignores the individual differences, or treats each set as completely separate leading to noisy estimates, as shown above. By assuming that each individual data set (each county in our case) is distributed according to a group distribution –
which we simultaneously estimate – we benefit from increased statistical power and smart regularization via the shrinkage effect. Probabilistic Programming in <a class="reference external" href="https://github.com/pymc-devs/pymc3">PyMC3</a> then makes Bayesian estimation of this model trivial.</p>
<p>As a follow-up we could also include other states into our model. For this we could add yet another layer to the hierarchy where each state is pooled at the country level. Finally, readers of my blog will notice that we didn’t use <code class="docutils literal notranslate"><span class="pre">glm()</span></code> here as it does not play nice with hierarchical models yet.</p>
</div>
<div class="section" id="References">
<h2>References<a class="headerlink" href="#References" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://rawgithub.com/twiecki/WhileMyMCMCGentlySamples/master/content/downloads/notebooks/GLM_hierarchical.ipynb">The underlying Notebook of this blog post</a></p></li>
<li><p>Blog post: <a class="reference external" href="http://twiecki.github.io/blog/2013/08/12/bayesian-glms-1/">The Inference Button: Bayesian GLMs made easy with PyMC3</a></p></li>
<li><p>Blog post: <a class="reference external" href="http://twiecki.github.io/blog/2013/08/27/bayesian-glms-2/">This world is far from Normal(ly distributed): Bayesian Robust Regression in PyMC3</a></p></li>
<li><p><a class="reference external" href="https://github.com/fonnesbeck/multilevel_modeling/">Chris Fonnesbeck repo containing a more extensive analysis</a></p></li>
<li><p>Blog post: <a class="reference external" href="http://doingbayesiandataanalysis.blogspot.com/2012/11/shrinkage-in-multi-level-hierarchical.html">Shrinkage in multi-level hierarchical models</a> by John Kruschke</p></li>
<li><p>Gelman, A.; Carlin; Stern; and Rubin, D., 2007, “Replication data for: Bayesian Data Analysis, Second Edition”,</p></li>
<li><p>Gelman, A., &amp; Hill, J. (2006). <a class="reference external" href="http://www.amazon.com/Analysis-Regression-Multilevel-Hierarchical-Models/dp/052168689X">Data Analysis Using Regression and Multilevel/Hierarchical Models (1st ed.). Cambridge University Press.</a></p></li>
<li><p>Gelman, A. (2006). Multilevel (Hierarchical) modeling: what it can and cannot do. Technometrics, 48(3), 432–435.</p></li>
</ul>
<div class="section" id="Acknowledgements">
<h3>Acknowledgements<a class="headerlink" href="#Acknowledgements" title="Permalink to this headline">¶</a></h3>
<p>Thanks to <a class="reference external" href="http://serre-lab.clps.brown.edu/person/imri-sofer/">Imri Sofer</a> for feedback and teaching us about the connections to random-effects models and <a class="reference external" href="http://cdasr.mclean.harvard.edu/index.php/about-us/current-lab-members/14-faculty/62-daniel-dillon">Dan Dillon</a> for useful comments on an earlier draft.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -n -u -v -iv -w
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
pymc3  3.9.0
numpy  1.18.5
theano 1.0.4
arviz  0.8.3
pandas 1.0.4
last updated: Mon Jun 15 2020

CPython 3.7.7
IPython 7.15.0
watermark 2.0.2
</pre></div></div>
</div>
</div>
</div>
</div>


    </div>
</div>
<div class="ui vertical footer segment">
    <div class="ui center aligned container">
        <a href="https://github.com/pymc-devs/pymc3"><i class="github icon large"></i></a>
        <a href="https://twitter.com/pymc_devs"><i class="twitter icon large"></i></a>
        <a href="https://discourse.pymc.io/"><i class="discourse icon large"></i></a>
    </div>
    <div class="ui center aligned container">This page uses <a href="https://analytics.google.com/">
    Google Analytics</a> to collect statistics. You can disable it by blocking
    the JavaScript coming from www.google-analytics.com.
    <script>
      (function() {
        var ga = document.createElement('script');
        ga.src = ('https:' == document.location.protocol ?
                  'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        ga.setAttribute('async', 'true');
        document.documentElement.firstChild.appendChild(ga);
      })();
    </script>
    </div>
    <div class="ui center aligned container">
        <p>
            &copy; Copyright 2018, The PyMC Development Team.
        </p>
        <p>
            Created using <a href="https://sphinx-doc.org/">Sphinx</a> 3.4.0.<br />
        </p>
    </div>
</div>
  </body>
</html>